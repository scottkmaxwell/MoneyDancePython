import typing
import java.io
import java.lang
import misc


class IntStream:
    def LA(self, i: int) -> int: ...
    
    def __init__(self) -> None: ...
    
    def consume(self) -> None: ...
    
    def getSourceName(self) -> str: ...
    
    def index(self) -> int: ...
    
    def mark(self) -> int: ...
    
    def release(self, i: int) -> None: ...
    
    def rewind(self) -> None: ...
    
    def seek(self, i: int) -> None: ...
    
    def size(self) -> int: ...
    
    
class CharStream(IntStream):
    EOF = -1
    
    def LT(self, i: int) -> int: ...
    
    def __init__(self) -> None: ...
    
    def getCharPositionInLine(self) -> int: ...
    
    def getLine(self) -> int: ...
    
    def setCharPositionInLine(self, i: int) -> None: ...
    
    def setLine(self, i: int) -> None: ...
    
    def substring(self, i: int, i2: int) -> str: ...
    
    
class ANTLRStringStream(CharStream):
    EOF = -1
    name: str
    
    def LA(self, i: int) -> int: ...
    
    def LT(self, i: int) -> int: ...
    
    def __init__(self) -> None: ...
    
    def consume(self) -> None: ...
    
    def getCharPositionInLine(self) -> int: ...
    
    def getLine(self) -> int: ...
    
    def getSourceName(self) -> str: ...
    
    def index(self) -> int: ...
    
    def mark(self) -> int: ...
    
    def release(self, i: int) -> None: ...
    
    def reset(self) -> None: ...
    
    def rewind(self) -> None: ...
    
    def seek(self, i: int) -> None: ...
    
    def setCharPositionInLine(self, i: int) -> None: ...
    
    def setLine(self, i: int) -> None: ...
    
    def size(self) -> int: ...
    
    def substring(self, i: int, i2: int) -> str: ...
    
    def toString(self) -> str: ...
    
    
class ANTLRFileStream(ANTLRStringStream):
    EOF = -1
    name: str
    
    def __init__(self, s: str) -> None: ...
    
    def getSourceName(self) -> str: ...
    
    def load(self, s: str, s2: str) -> None: ...
    
    
class ANTLRReaderStream(ANTLRStringStream):
    EOF = -1
    INITIAL_BUFFER_SIZE = 1024
    READ_BUFFER_SIZE = 1024
    name: str
    
    def __init__(self) -> None: ...
    
    def load(self, j: java.io.Reader, i: int, i2: int) -> None: ...
    
    
class ANTLRInputStream(ANTLRReaderStream):
    EOF = -1
    INITIAL_BUFFER_SIZE = 1024
    READ_BUFFER_SIZE = 1024
    name: str
    
    def __init__(self) -> None: ...
    
    
class BaseRecognizer:
    DEFAULT_TOKEN_CHANNEL = 0
    HIDDEN = 99
    INITIAL_FOLLOW_STACK_SIZE = 100
    MEMO_RULE_FAILED = -2
    MEMO_RULE_UNKNOWN = -1
    NEXT_TOKEN_RULE_NAME = u'nextToken'
    
    def __init__(self) -> None: ...
    
    def alreadyParsedRule(self, intStream: IntStream, i: int) -> bool: ...
    
    def beginResync(self) -> None: ...
    
    def consumeUntil(self, intStream: IntStream, i: int) -> None: ...
    
    def displayRecognitionError(self, t: typing.List[str], recognitionException: 'RecognitionException') -> None: ...
    
    def emitErrorMessage(self, s: str) -> None: ...
    
    def endResync(self) -> None: ...
    
    def failed(self) -> bool: ...
    
    def getBacktrackingLevel(self) -> int: ...
    
    def getErrorHeader(self, recognitionException: 'RecognitionException') -> str: ...
    
    def getErrorMessage(self, recognitionException: 'RecognitionException', t: typing.List[str]) -> str: ...
    
    def getGrammarFileName(self) -> str: ...
    
    def getNumberOfSyntaxErrors(self) -> int: ...
    
    def getRuleInvocationStack(self) -> typing.List[str]: ...
    
    def getRuleMemoization(self, i: int, i2: int) -> int: ...
    
    def getRuleMemoizationCacheSize(self) -> int: ...
    
    def getSourceName(self) -> str: ...
    
    def getTokenErrorDisplay(self, token: 'Token') -> str: ...
    
    def getTokenNames(self) -> typing.List[str]: ...
    
    def match(self, intStream: IntStream, i: int, bitSet: 'BitSet') -> object: ...
    
    def matchAny(self, intStream: IntStream) -> None: ...
    
    def memoize(self, intStream: IntStream, i: int, i2: int) -> None: ...
    
    def mismatchIsMissingToken(self, intStream: IntStream, bitSet: 'BitSet') -> bool: ...
    
    def mismatchIsUnwantedToken(self, intStream: IntStream, i: int) -> bool: ...
    
    def recover(self, intStream: IntStream, recognitionException: 'RecognitionException') -> None: ...
    
    def recoverFromMismatchedSet(self, intStream: IntStream, recognitionException: 'RecognitionException', bitSet: 'BitSet') -> object: ...
    
    def reportError(self, recognitionException: 'RecognitionException') -> None: ...
    
    def reset(self) -> None: ...
    
    def setBacktrackingLevel(self, i: int) -> None: ...
    
    def toStrings(self, t: typing.List['org.antlr.runtime.Token']) -> typing.List[str]: ...
    
    def traceIn(self, s: str, i: int, o: object) -> None: ...
    
    def traceOut(self, s: str, i: int, o: object) -> None: ...
    
    
class BitSet(java.lang.Cloneable):
    def __init__(self) -> None: ...
    
    def add(self, i: int) -> None: ...
    
    def clone(self) -> object: ...
    
    def equals(self, o: object) -> bool: ...
    
    def growToInclude(self, i: int) -> None: ...
    
    def isNil(self) -> bool: ...
    
    def lengthInLongWords(self) -> int: ...
    
    def member(self, i: int) -> bool: ...
    
    def numBits(self) -> int: ...
    
    @staticmethod
    def of(i: int) -> 'BitSet': ...
    
    def or(self, bitSet: 'BitSet') -> 'BitSet': ...
    
    def orInPlace(self, bitSet: 'BitSet') -> None: ...
    
    def remove(self, i: int) -> None: ...
    
    def size(self) -> int: ...
    
    def toArray(self) -> typing.List[int]: ...
    
    def toPackedArray(self) -> typing.List[int]: ...
    
    def toString(self) -> str: ...
    
    
class TokenStream(IntStream):
    def LT(self, i: int) -> 'Token': ...
    
    def __init__(self) -> None: ...
    
    def get(self, i: int) -> 'Token': ...
    
    def getTokenSource(self) -> 'TokenSource': ...
    
    def range(self) -> int: ...
    
    def toString(self, i: int, i2: int) -> str: ...
    
    
class BufferedTokenStream(TokenStream):
    def LA(self, i: int) -> int: ...
    
    def LT(self, i: int) -> 'Token': ...
    
    def __init__(self) -> None: ...
    
    def consume(self) -> None: ...
    
    def fill(self) -> None: ...
    
    def get(self, i: int) -> 'Token': ...
    
    def getSourceName(self) -> str: ...
    
    def getTokenSource(self) -> 'TokenSource': ...
    
    def getTokens(self) -> typing.List['org.antlr.runtime.Token']: ...
    
    def index(self) -> int: ...
    
    def mark(self) -> int: ...
    
    def range(self) -> int: ...
    
    def release(self, i: int) -> None: ...
    
    def reset(self) -> None: ...
    
    def rewind(self) -> None: ...
    
    def seek(self, i: int) -> None: ...
    
    def setTokenSource(self, tokenSource: 'TokenSource') -> None: ...
    
    def size(self) -> int: ...
    
    def toString(self) -> str: ...
    
    
class CharStreamState:
    def __init__(self) -> None: ...
    
    
class Token:
    DEFAULT_CHANNEL = 0
    DOWN = 2
    EOF = -1
    EOR_TOKEN_TYPE = 1
    HIDDEN_CHANNEL = 99
    INVALID_TOKEN = "[@-1,0:0='<no text>',<0>,0:-1]"
    INVALID_TOKEN_TYPE = 0
    MIN_TOKEN_TYPE = 4
    SKIP_TOKEN = "[@-1,0:0='<no text>',<0>,0:-1]"
    UP = 3
    
    def __init__(self) -> None: ...
    
    def getChannel(self) -> int: ...
    
    def getCharPositionInLine(self) -> int: ...
    
    def getInputStream(self) -> CharStream: ...
    
    def getLine(self) -> int: ...
    
    def getText(self) -> str: ...
    
    def getTokenIndex(self) -> int: ...
    
    def getType(self) -> int: ...
    
    def setChannel(self, i: int) -> None: ...
    
    def setCharPositionInLine(self, i: int) -> None: ...
    
    def setInputStream(self, charStream: CharStream) -> None: ...
    
    def setLine(self, i: int) -> None: ...
    
    def setText(self, s: str) -> None: ...
    
    def setTokenIndex(self, i: int) -> None: ...
    
    def setType(self, i: int) -> None: ...
    
    
class ClassicToken(Token):
    DEFAULT_CHANNEL = 0
    DOWN = 2
    EOF = -1
    EOR_TOKEN_TYPE = 1
    HIDDEN_CHANNEL = 99
    INVALID_TOKEN = "[@-1,0:0='<no text>',<0>,0:-1]"
    INVALID_TOKEN_TYPE = 0
    MIN_TOKEN_TYPE = 4
    SKIP_TOKEN = "[@-1,0:0='<no text>',<0>,0:-1]"
    UP = 3
    
    def __init__(self, i: int) -> None: ...
    
    def getChannel(self) -> int: ...
    
    def getCharPositionInLine(self) -> int: ...
    
    def getInputStream(self) -> CharStream: ...
    
    def getLine(self) -> int: ...
    
    def getText(self) -> str: ...
    
    def getTokenIndex(self) -> int: ...
    
    def getType(self) -> int: ...
    
    def setChannel(self, i: int) -> None: ...
    
    def setCharPositionInLine(self, i: int) -> None: ...
    
    def setInputStream(self, charStream: CharStream) -> None: ...
    
    def setLine(self, i: int) -> None: ...
    
    def setText(self, s: str) -> None: ...
    
    def setTokenIndex(self, i: int) -> None: ...
    
    def setType(self, i: int) -> None: ...
    
    def toString(self) -> str: ...
    
    
class CommonToken(Token, java.io.Serializable):
    DEFAULT_CHANNEL = 0
    DOWN = 2
    EOF = -1
    EOR_TOKEN_TYPE = 1
    HIDDEN_CHANNEL = 99
    INVALID_TOKEN = "[@-1,0:0='<no text>',<0>,0:-1]"
    INVALID_TOKEN_TYPE = 0
    MIN_TOKEN_TYPE = 4
    SKIP_TOKEN = "[@-1,0:0='<no text>',<0>,0:-1]"
    UP = 3
    
    def __init__(self, i: int) -> None: ...
    
    def getChannel(self) -> int: ...
    
    def getCharPositionInLine(self) -> int: ...
    
    def getInputStream(self) -> CharStream: ...
    
    def getLine(self) -> int: ...
    
    def getStartIndex(self) -> int: ...
    
    def getStopIndex(self) -> int: ...
    
    def getText(self) -> str: ...
    
    def getTokenIndex(self) -> int: ...
    
    def getType(self) -> int: ...
    
    def setChannel(self, i: int) -> None: ...
    
    def setCharPositionInLine(self, i: int) -> None: ...
    
    def setInputStream(self, charStream: CharStream) -> None: ...
    
    def setLine(self, i: int) -> None: ...
    
    def setStartIndex(self, i: int) -> None: ...
    
    def setStopIndex(self, i: int) -> None: ...
    
    def setText(self, s: str) -> None: ...
    
    def setTokenIndex(self, i: int) -> None: ...
    
    def setType(self, i: int) -> None: ...
    
    def toString(self) -> str: ...
    
    
class CommonTokenStream(BufferedTokenStream):
    def LT(self, i: int) -> Token: ...
    
    def __init__(self) -> None: ...
    
    def consume(self) -> None: ...
    
    def getNumberOfOnChannelTokens(self) -> int: ...
    
    def reset(self) -> None: ...
    
    def setTokenSource(self, tokenSource: 'TokenSource') -> None: ...
    
    
class DFA:
    debug = False
    
    def __init__(self) -> None: ...
    
    def getDescription(self) -> str: ...
    
    def predict(self, intStream: IntStream) -> int: ...
    
    def specialStateTransition(self, i: int, intStream: IntStream) -> int: ...
    
    @staticmethod
    def unpackEncodedString(s: str) -> typing.List[int]: ...
    
    @staticmethod
    def unpackEncodedStringToUnsignedChars(s: str) -> typing.List[str]: ...
    
    
class RecognitionException(Exception):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    index: int
    input: IntStream
    line: int
    node: object
    token: Token
    
    def __init__(self) -> None: ...
    
    def getUnexpectedType(self) -> int: ...
    
    
class EarlyExitException(RecognitionException):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    decisionNumber: int
    index: int
    input: IntStream
    line: int
    node: object
    token: Token
    
    def __init__(self) -> None: ...
    
    
class FailedPredicateException(RecognitionException):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    index: int
    input: IntStream
    line: int
    node: object
    predicateText: str
    ruleName: str
    token: Token
    
    def __init__(self) -> None: ...
    
    def toString(self) -> str: ...
    
    
class LegacyCommonTokenStream(TokenStream):
    def LA(self, i: int) -> int: ...
    
    def LT(self, i: int) -> Token: ...
    
    def __init__(self) -> None: ...
    
    def consume(self) -> None: ...
    
    def discardOffChannelTokens(self, b: bool) -> None: ...
    
    def discardTokenType(self, i: int) -> None: ...
    
    def get(self, i: int) -> Token: ...
    
    def getSourceName(self) -> str: ...
    
    def getTokenSource(self) -> 'TokenSource': ...
    
    def getTokens(self) -> typing.List['org.antlr.runtime.Token']: ...
    
    def index(self) -> int: ...
    
    def mark(self) -> int: ...
    
    def range(self) -> int: ...
    
    def release(self, i: int) -> None: ...
    
    def reset(self) -> None: ...
    
    def rewind(self) -> None: ...
    
    def seek(self, i: int) -> None: ...
    
    def setTokenSource(self, tokenSource: 'TokenSource') -> None: ...
    
    def setTokenTypeChannel(self, i: int, i2: int) -> None: ...
    
    def size(self) -> int: ...
    
    def toString(self) -> str: ...
    
    
class TokenSource:
    def __init__(self) -> None: ...
    
    def getSourceName(self) -> str: ...
    
    def nextToken(self) -> Token: ...
    
    
class Lexer(BaseRecognizer, TokenSource):
    DEFAULT_TOKEN_CHANNEL = 0
    HIDDEN = 99
    INITIAL_FOLLOW_STACK_SIZE = 100
    MEMO_RULE_FAILED = -2
    MEMO_RULE_UNKNOWN = -1
    NEXT_TOKEN_RULE_NAME = u'nextToken'
    
    def __init__(self) -> None: ...
    
    def emit(self) -> Token: ...
    
    def getCharErrorDisplay(self, i: int) -> str: ...
    
    def getCharIndex(self) -> int: ...
    
    def getCharPositionInLine(self) -> int: ...
    
    def getCharStream(self) -> CharStream: ...
    
    def getEOFToken(self) -> Token: ...
    
    def getErrorMessage(self, recognitionException: RecognitionException, t: typing.List[str]) -> str: ...
    
    def getLine(self) -> int: ...
    
    def getSourceName(self) -> str: ...
    
    def getText(self) -> str: ...
    
    def mTokens(self) -> None: ...
    
    def match(self, i: int) -> None: ...
    
    def matchAny(self) -> None: ...
    
    def matchRange(self, i: int, i2: int) -> None: ...
    
    def nextToken(self) -> Token: ...
    
    def recover(self, recognitionException: RecognitionException) -> None: ...
    
    def reportError(self, recognitionException: RecognitionException) -> None: ...
    
    def reset(self) -> None: ...
    
    def setCharStream(self, charStream: CharStream) -> None: ...
    
    def setText(self, s: str) -> None: ...
    
    def skip(self) -> None: ...
    
    def traceIn(self, s: str, i: int) -> None: ...
    
    def traceOut(self, s: str, i: int) -> None: ...
    
    
class MismatchedSetException(RecognitionException):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    expecting: BitSet
    index: int
    input: IntStream
    line: int
    node: object
    token: Token
    
    def __init__(self) -> None: ...
    
    def toString(self) -> str: ...
    
    
class MismatchedNotSetException(MismatchedSetException):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    expecting: BitSet
    index: int
    input: IntStream
    line: int
    node: object
    token: Token
    
    def __init__(self) -> None: ...
    
    def toString(self) -> str: ...
    
    
class MismatchedRangeException(RecognitionException):
    a: int
    approximateLineInfo: bool
    b: int
    c: int
    charPositionInLine: int
    index: int
    input: IntStream
    line: int
    node: object
    token: Token
    
    def __init__(self) -> None: ...
    
    def toString(self) -> str: ...
    
    
class MismatchedTokenException(RecognitionException):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    expecting: int
    index: int
    input: IntStream
    line: int
    node: object
    token: Token
    
    def __init__(self) -> None: ...
    
    def toString(self) -> str: ...
    
    
class MismatchedTreeNodeException(RecognitionException):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    expecting: int
    index: int
    input: IntStream
    line: int
    node: object
    token: Token
    
    def __init__(self) -> None: ...
    
    def toString(self) -> str: ...
    
    
class MissingTokenException(MismatchedTokenException):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    expecting: int
    index: int
    input: IntStream
    inserted: object
    line: int
    node: object
    token: Token
    
    def __init__(self) -> None: ...
    
    def getMissingType(self) -> int: ...
    
    def toString(self) -> str: ...
    
    
class NoViableAltException(RecognitionException):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    decisionNumber: int
    grammarDecisionDescription: str
    index: int
    input: IntStream
    line: int
    node: object
    stateNumber: int
    token: Token
    
    def __init__(self) -> None: ...
    
    def toString(self) -> str: ...
    
    
class Parser(BaseRecognizer):
    DEFAULT_TOKEN_CHANNEL = 0
    HIDDEN = 99
    INITIAL_FOLLOW_STACK_SIZE = 100
    MEMO_RULE_FAILED = -2
    MEMO_RULE_UNKNOWN = -1
    NEXT_TOKEN_RULE_NAME = u'nextToken'
    input: TokenStream
    
    def __init__(self, tokenStream: TokenStream) -> None: ...
    
    def getSourceName(self) -> str: ...
    
    def getTokenStream(self) -> TokenStream: ...
    
    def reset(self) -> None: ...
    
    def setTokenStream(self, tokenStream: TokenStream) -> None: ...
    
    def traceIn(self, s: str, i: int) -> None: ...
    
    def traceOut(self, s: str, i: int) -> None: ...
    
    
class RuleReturnScope:
    def __init__(self) -> None: ...
    
    def getStart(self) -> object: ...
    
    def getStop(self) -> object: ...
    
    def getTemplate(self) -> object: ...
    
    def getTree(self) -> object: ...
    
    
class ParserRuleReturnScope(RuleReturnScope):
    start: Token
    stop: Token
    
    def __init__(self) -> None: ...
    
    def getStart(self) -> object: ...
    
    def getStop(self) -> object: ...
    
    def getTree(self) -> object: ...
    
    
class RecognizerSharedState:
    _fsp: int
    backtracking: int
    channel: int
    errorRecovery: bool
    failed: bool
    following: typing.List[BitSet]
    lastErrorIndex: int
    ruleMemo: typing.List[dict]
    syntaxErrors: int
    text: str
    token: Token
    tokenStartCharIndex: int
    tokenStartCharPositionInLine: int
    tokenStartLine: int
    type: int
    
    def __init__(self) -> None: ...
    
    
class SerializedGrammar:
    COOKIE = u'$ANTLR'
    FORMAT_VERSION = 1
    name: str
    rules: list
    type: str
    
    def __init__(self, s: str) -> None: ...
    
    def toString(self) -> str: ...
    
    
class TokenRewriteStream(CommonTokenStream):
    DEFAULT_PROGRAM_NAME = u'default'
    MIN_TOKEN_INDEX = 0
    PROGRAM_INIT_SIZE = 100
    
    def __init__(self) -> None: ...
    
    def delete(self, i: int) -> None: ...
    
    def deleteProgram(self) -> None: ...
    
    def getLastRewriteTokenIndex(self) -> int: ...
    
    def insertAfter(self, i: int, o: object) -> None: ...
    
    def insertBefore(self, i: int, o: object) -> None: ...
    
    def replace(self, i: int, o: object) -> None: ...
    
    def rollback(self, i: int) -> None: ...
    
    def toDebugString(self) -> str: ...
    
    def toOriginalString(self) -> str: ...
    
    def toString(self) -> str: ...
    
    
    class RewriteOperation:
        def __init__(self) -> None: ...
        
        def execute(self, j: java.lang.StringBuffer) -> int: ...
        
        def toString(self) -> str: ...
        
        
    
class UnbufferedTokenStream(TokenStream, misc.LookaheadStream):
    UNINITIALIZED_EOF_ELEMENT_INDEX = 2147483647
    eof: object
    
    def LA(self, i: int) -> int: ...
    
    def __init__(self, tokenSource: TokenSource) -> None: ...
    
    def get(self, i: int) -> Token: ...
    
    def getSourceName(self) -> str: ...
    
    def getTokenSource(self) -> TokenSource: ...
    
    def isEOF(self, token: Token) -> bool: ...
    
    def nextElement(self) -> object: ...
    
    
class UnwantedTokenException(MismatchedTokenException):
    approximateLineInfo: bool
    c: int
    charPositionInLine: int
    expecting: int
    index: int
    input: IntStream
    line: int
    node: object
    token: Token
    
    def __init__(self) -> None: ...
    
    def getUnexpectedToken(self) -> Token: ...
    
    def toString(self) -> str: ...
    
    
